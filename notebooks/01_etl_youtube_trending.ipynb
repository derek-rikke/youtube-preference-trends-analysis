{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39005ac9",
   "metadata": {},
   "source": [
    "# YouTube Trending ETL: Exploring Global Cultural Preferences\n",
    "\n",
    "This notebook processes daily trending YouTube video data from 113 countries to prepare it for analysis in Tableau. The objective of this project is to uncover global cultural preferences by examining patterns in video titles, sentiment, engagement metrics, and publishing behavior.\n",
    "\n",
    "The full dataset is updated daily and sourced from Kaggle.\n",
    "\n",
    "**Project Goals:**\n",
    "- Download and validate the raw dataset\n",
    "- Clean and standardize the data\n",
    "- Engineer relevant features for analysis\n",
    "- Export the processed dataset for visualization\n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasets/asaniczka/trending-youtube-videos-113-countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f214f",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "In this section, we import all necessary Python libraries for data processing, text analysis, and emoji detection. We also configure the notebook to ensure that all file paths are relative to the project root directory, rather than the `notebooks/` folder. This allows consistent file organization when reading or writing to the `data/` and `processed/` directories.\n",
    "\n",
    "All required dependencies are listed in the `requirements.txt` file in the root directory. To install them, run:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465b39cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\derek\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\derek\\projects\\youtube-preference-trends-analysis\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Text Analysis\n",
    "from textblob import TextBlob\n",
    "import emoji\n",
    "\n",
    "# Dataset Access\n",
    "import kagglehub\n",
    "\n",
    "# Ensure paths are relative to the project root, not the notebook location\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory to project root (parent of /notebooks)\n",
    "project_root = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"Working directory set to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a70afe",
   "metadata": {},
   "source": [
    "## Downloading the Dataset\n",
    "\n",
    "We use the `kagglehub` library to programmatically download the latest version of the dataset from Kaggle. This ensures we always work with the most recent snapshot. The downloaded files will be cached locally, but for clarity and reproducibility, we will move the dataset into the `data/raw/` directory once downloaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b41ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: C:\\Users\\derek\\.cache\\kagglehub\\datasets\\asaniczka\\trending-youtube-videos-113-countries\\versions\\644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trending_yt_videos_113_countries.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset using kagglehub\n",
    "dataset_path = kagglehub.dataset_download(\"asaniczka/trending-youtube-videos-113-countries\")\n",
    "\n",
    "print(\"Dataset downloaded to:\", dataset_path)\n",
    "\n",
    "# List the contents to verify\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba7716",
   "metadata": {},
   "source": [
    "## Organizing the Raw Data\n",
    "\n",
    "After downloading the dataset using `kagglehub`, we relocate the CSV file to a dedicated `data/raw/` directory. This improves reproducibility and organization by separating raw inputs from processed outputs. It also allows us to version and reference the dataset consistently across the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126f509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied file to: data\\raw\\trending_yt_videos_113_countries.csv\n"
     ]
    }
   ],
   "source": [
    "# Create raw data directory if it doesn't exist\n",
    "raw_dir = os.path.join(\"data\", \"raw\")\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "# Define source and destination paths\n",
    "src_file = os.path.join(dataset_path, \"trending_yt_videos_113_countries.csv\")\n",
    "dst_file = os.path.join(raw_dir, \"trending_yt_videos_113_countries.csv\")\n",
    "\n",
    "# Copy the file to the data/raw/ directory\n",
    "if not os.path.exists(dst_file):\n",
    "    import shutil\n",
    "    shutil.copy2(src_file, dst_file)\n",
    "    print(\"Copied file to:\", dst_file)\n",
    "else:\n",
    "    print(\"File already exists in:\", dst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a710c63",
   "metadata": {},
   "source": [
    "## Loading and Previewing the Raw Data\n",
    "\n",
    "We now load the raw CSV file into a Pandas DataFrame and inspect its structure. This step helps verify the format and identify any obvious issues such as missing values, inconsistent columns, or encoding problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329ff57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3594728, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3594728 entries, 0 to 3594727\n",
      "Data columns (total 18 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   title            object\n",
      " 1   channel_name     object\n",
      " 2   daily_rank       int64 \n",
      " 3   daily_movement   int64 \n",
      " 4   weekly_movement  int64 \n",
      " 5   snapshot_date    object\n",
      " 6   country          object\n",
      " 7   view_count       int64 \n",
      " 8   like_count       int64 \n",
      " 9   comment_count    int64 \n",
      " 10  description      object\n",
      " 11  thumbnail_url    object\n",
      " 12  video_id         object\n",
      " 13  channel_id       object\n",
      " 14  video_tags       object\n",
      " 15  kind             object\n",
      " 16  publish_date     object\n",
      " 17  langauge         object\n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 493.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>daily_rank</th>\n",
       "      <th>daily_movement</th>\n",
       "      <th>weekly_movement</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>country</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>description</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>kind</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>langauge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Master H - Haudi Kudiwa (Official Video) ft. T...</td>\n",
       "      <td>Master H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>ZW</td>\n",
       "      <td>1109150</td>\n",
       "      <td>32819</td>\n",
       "      <td>3103</td>\n",
       "      <td>Artist  : @master_H_official  Ft @Bottom_Camp ...</td>\n",
       "      <td>https://i.ytimg.com/vi/rgwL9V3t1og/mqdefault.jpg</td>\n",
       "      <td>rgwL9V3t1og</td>\n",
       "      <td>UC5jrU8WxzE16gPTnlqQAqew</td>\n",
       "      <td>#zimbabwe #music #trending #masterh #anika #da...</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>2025-07-04 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EA SPORTS FC 26 | Official Reveal Trailer</td>\n",
       "      <td>EA SPORTS FC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>ZW</td>\n",
       "      <td>8365074</td>\n",
       "      <td>266900</td>\n",
       "      <td>22703</td>\n",
       "      <td>Innovation powered by you in every mode. The C...</td>\n",
       "      <td>https://i.ytimg.com/vi/TSi0iJYSQ24/mqdefault.jpg</td>\n",
       "      <td>TSi0iJYSQ24</td>\n",
       "      <td>UCoyaxd5LQSuP4ChkxK0pnZQ</td>\n",
       "      <td>yt:cc=on, EA SPORTS FC, FC 25, EA FC, EA FC re...</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>2025-07-16 00:00:00+00:00</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[LIVE] Manchester United vs Leeds United Pre-s...</td>\n",
       "      <td>Kampleng Com</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>ZW</td>\n",
       "      <td>143492</td>\n",
       "      <td>617</td>\n",
       "      <td>3</td>\n",
       "      <td>[LIVE] Manchester United vs Leeds United Pre-s...</td>\n",
       "      <td>https://i.ytimg.com/vi/MjpunTTElhY/mqdefault.jpg</td>\n",
       "      <td>MjpunTTElhY</td>\n",
       "      <td>UCdMJwGhTUhAzk1ksH6iHjUw</td>\n",
       "      <td>manchester united vs leeds united, manchester ...</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>2025-07-19 00:00:00+00:00</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  channel_name  \\\n",
       "0  Master H - Haudi Kudiwa (Official Video) ft. T...      Master H   \n",
       "1          EA SPORTS FC 26 | Official Reveal Trailer  EA SPORTS FC   \n",
       "2  [LIVE] Manchester United vs Leeds United Pre-s...  Kampleng Com   \n",
       "\n",
       "   daily_rank  daily_movement  weekly_movement snapshot_date country  \\\n",
       "0           1               0               49    2025-07-25      ZW   \n",
       "1           2               0               23    2025-07-25      ZW   \n",
       "2           3               0               47    2025-07-25      ZW   \n",
       "\n",
       "   view_count  like_count  comment_count  \\\n",
       "0     1109150       32819           3103   \n",
       "1     8365074      266900          22703   \n",
       "2      143492         617              3   \n",
       "\n",
       "                                         description  \\\n",
       "0  Artist  : @master_H_official  Ft @Bottom_Camp ...   \n",
       "1  Innovation powered by you in every mode. The C...   \n",
       "2  [LIVE] Manchester United vs Leeds United Pre-s...   \n",
       "\n",
       "                                      thumbnail_url     video_id  \\\n",
       "0  https://i.ytimg.com/vi/rgwL9V3t1og/mqdefault.jpg  rgwL9V3t1og   \n",
       "1  https://i.ytimg.com/vi/TSi0iJYSQ24/mqdefault.jpg  TSi0iJYSQ24   \n",
       "2  https://i.ytimg.com/vi/MjpunTTElhY/mqdefault.jpg  MjpunTTElhY   \n",
       "\n",
       "                 channel_id  \\\n",
       "0  UC5jrU8WxzE16gPTnlqQAqew   \n",
       "1  UCoyaxd5LQSuP4ChkxK0pnZQ   \n",
       "2  UCdMJwGhTUhAzk1ksH6iHjUw   \n",
       "\n",
       "                                          video_tags           kind  \\\n",
       "0  #zimbabwe #music #trending #masterh #anika #da...  youtube#video   \n",
       "1  yt:cc=on, EA SPORTS FC, FC 25, EA FC, EA FC re...  youtube#video   \n",
       "2  manchester united vs leeds united, manchester ...  youtube#video   \n",
       "\n",
       "                publish_date langauge  \n",
       "0  2025-07-04 00:00:00+00:00      NaN  \n",
       "1  2025-07-16 00:00:00+00:00       en  \n",
       "2  2025-07-19 00:00:00+00:00       id  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the raw data directory\n",
    "csv_file = os.path.join(\"data\", \"raw\", \"trending_yt_videos_113_countries.csv\")\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Basic inspection\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facad53",
   "metadata": {},
   "source": [
    "## Data Cleaning and Standardization\n",
    "\n",
    "This section focuses on preparing the dataset for analysis by resolving common data quality issues. Specifically, we:\n",
    "- Drop duplicate records based on `video_id` and `snapshot_date`\n",
    "- Remove rows with missing required fields\n",
    "- Correct inconsistent column names\n",
    "- Standardize text fields by trimming whitespace\n",
    "- Convert date fields to proper datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950ee120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop exact duplicate rows (if any)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop duplicate trending entries for the same video on the same day\n",
    "df.drop_duplicates(subset=[\"video_id\", \"snapshot_date\"], inplace=True)\n",
    "\n",
    "# Drop rows missing critical fields (video title, country, or view count)\n",
    "df.dropna(subset=[\"title\", \"country\", \"view_count\"], inplace=True)\n",
    "\n",
    "# Fix column name typo (\"langauge\" → \"language\")\n",
    "df.rename(columns={\"langauge\": \"language\"}, inplace=True)\n",
    "\n",
    "# Standardize string fields\n",
    "df[\"title\"] = df[\"title\"].str.strip()\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\").str.strip()\n",
    "df[\"channel_name\"] = df[\"channel_name\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3658c",
   "metadata": {},
   "source": [
    "### Parsing Date Columns\n",
    "\n",
    "We convert the `snapshot_date` and `publish_date` fields to datetime format. This allows for accurate calculation of time-based features in the next stage of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806e9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date columns\n",
    "df[\"snapshot_date\"] = pd.to_datetime(df[\"snapshot_date\"], errors=\"coerce\")\n",
    "df[\"publish_date\"] = pd.to_datetime(df[\"publish_date\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# Drop rows with unparseable dates, if any\n",
    "df.dropna(subset=[\"snapshot_date\", \"publish_date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258d478",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "In this section, we derive new features to capture patterns in title structure, engagement behavior, and publishing timelines. These features will support cross-country comparisons of content preferences and viewer interaction styles.\n",
    "\n",
    "The engineered features include:\n",
    "- Title characteristics (length, emoji usage, presence of a question)\n",
    "- Sentiment of the title\n",
    "- Engagement ratios (likes/views, comments/views)\n",
    "- Temporal features (days between publish and trending, day of week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d36dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title length (characters and word count)\n",
    "df[\"title_length_chars\"] = df[\"title\"].str.len()\n",
    "df[\"title_word_count\"] = df[\"title\"].str.split().str.len()\n",
    "\n",
    "# Emoji presence in title\n",
    "df[\"title_has_emoji\"] = df[\"title\"].apply(lambda x: any(char in emoji.EMOJI_DATA for char in x))\n",
    "\n",
    "# Question mark in title\n",
    "df[\"title_has_question\"] = df[\"title\"].str.contains(r\"\\?\", regex=True)\n",
    "\n",
    "# Sentiment polarity of title\n",
    "df[\"title_sentiment\"] = df[\"title\"].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0559cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid division errors\n",
    "df[\"like_count\"] = df[\"like_count\"].replace(0, np.nan)\n",
    "df[\"comment_count\"] = df[\"comment_count\"].replace(0, np.nan)\n",
    "df[\"view_count\"] = df[\"view_count\"].replace(0, np.nan)\n",
    "\n",
    "# Engagement ratios\n",
    "df[\"like_ratio\"] = df[\"like_count\"] / df[\"view_count\"]\n",
    "df[\"comment_ratio\"] = df[\"comment_count\"] / df[\"view_count\"]\n",
    "\n",
    "# Drop rows where view_count is missing or zero after replacement\n",
    "df.dropna(subset=[\"view_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ab1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both to timezone-naive datetime\n",
    "df[\"publish_date\"] = df[\"publish_date\"].dt.tz_localize(None)\n",
    "df[\"snapshot_date\"] = pd.to_datetime(df[\"snapshot_date\"])  # already naive, but reparse just in case\n",
    "\n",
    "# Compute days between publish and snapshot\n",
    "df[\"days_since_publish\"] = (df[\"snapshot_date\"] - df[\"publish_date\"]).dt.days\n",
    "\n",
    "# Day of week published\n",
    "df[\"publish_day_of_week\"] = df[\"publish_date\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a691e1",
   "metadata": {},
   "source": [
    "## Exporting the Processed Dataset\n",
    "\n",
    "With all features engineered and the dataset cleaned, we now export the final data to a CSV file for use in Tableau. The exported file will include all video-level records, enriched with derived features such as title sentiment, engagement ratios, and temporal indicators.\n",
    "\n",
    "We also generate an optional aggregated dataset that summarizes feature values by country. This can support country-level comparisons in Tableau.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cade811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported full enriched dataset to: processed\\trending_youtube_enriched.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the processed data directory if it doesn't exist\n",
    "os.makedirs(\"processed\", exist_ok=True)\n",
    "\n",
    "# Export the full cleaned dataset\n",
    "output_path_full = os.path.join(\"processed\", \"trending_youtube_enriched.csv\")\n",
    "df.to_csv(output_path_full, index=False)\n",
    "\n",
    "print(\"Exported full enriched dataset to:\", output_path_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
